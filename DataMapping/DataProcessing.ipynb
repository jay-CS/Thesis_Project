{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert everything to JSON \n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "# from os import path, mkdir\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def convertoJson():\n",
    "    with open('/Users/sloth/Desktop/CS271/271_project/DataMapping/keystroke_data_100.json', 'x') as F:\n",
    "        # Use the json dumps method to write the list to disk\n",
    "        all_data = {}\n",
    "        for i in range(1,76):\n",
    "            s = \"00\" + str(i) if i < 10 else \"0\" + str(i)\n",
    "            all_files = glob.glob(\"/Users/sloth/Desktop/CS271/271_project/DataMapping/CNN/100/%s/*\"%(s))\n",
    "            data = []\n",
    "            for file in all_files:\n",
    "                data.append(list(np.load(file)))\n",
    "            all_data[\"user\"+str(i)] = data\n",
    "        F.write(json.dumps(all_data))\n",
    "\n",
    "def read_data(path):\n",
    "    \"\"\" Reads the data file and returns as a dictionary \"\"\"\n",
    "    with open(path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "def get_pos_neg(data, subject,count):\n",
    "    \"\"\" Returns positive and negative data for a given subject\"\"\"\n",
    "    x_pos = data[subject]\n",
    "    x_neg = []\n",
    "    for s in range(1,len(data)+1):\n",
    "        # if s != count and x_neg_len > 0:\n",
    "        #     x_neg.extend(data[\"user\"+str(s)][:1])\n",
    "        #     x_neg_len -= 2\n",
    "        if s != count:\n",
    "            x_neg.extend(data[\"user\"+str(s)][:10])\n",
    "    return x_pos.copy(), x_neg.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each folder, and other samples from CNN/75/ folder, scale it, and use it to train the mdoels \n",
    "\n",
    "from os import path, mkdir\n",
    "def partition_data_balanced(p):\n",
    "    \"\"\" Partitions the data in class balanced form and saves in files \n",
    "    Utilizes all 400 of the positive samples, and randomly selects \n",
    "    400 negative samples to produce the subset\"\"\"\n",
    "    data = read_data(p)\n",
    "    scaler = StandardScaler()\n",
    "    count = 1\n",
    "    for s in data:\n",
    "        x_pos, x_neg = get_pos_neg(data, s,count)\n",
    "        x = []\n",
    "        y = []\n",
    "        x.extend(x_pos)\n",
    "        y.extend([1 for _ in range(len(x_pos))] + [0 for _ in range(len(x_neg)-1)])\n",
    "        for _ in range(len(x_neg)-1):\n",
    "            r = np.random.randint(1, len(x_neg))\n",
    "            x.append(x_neg.pop(r))\n",
    "        # print(len(x))\n",
    "        \n",
    "        X = np.array(x, dtype = 'float64')\n",
    "        Y = np.array(y,dtype = 'float64')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
    "        data_dir = \"/Users/sloth/Desktop/CS271/271_project/DataMapping/balanced_new_data_\" + str(p.split(\"_\")[-1].split(\".\")[0]) + \"/\"\n",
    "        if not path.isdir(data_dir):\n",
    "            mkdir(data_dir)\n",
    "        if not path.isdir(data_dir + \"/\" + s):\n",
    "            mkdir(data_dir + \"/\" + s)\n",
    "            \n",
    "        scaler.fit(x_train)\n",
    "        x_train_scale = scaler.transform(x_train)\n",
    "        x_test_scale = scaler.transform(x_test)\n",
    "        np.save(data_dir + \"/\" + s + \"/x_train.npy\", x_train_scale)\n",
    "        np.save(data_dir + \"/\" + s + \"/x_test.npy\", x_test_scale)\n",
    "        np.save(data_dir + \"/\" + s + \"/y_train.npy\", y_train)\n",
    "        np.save(data_dir + \"/\" + s + \"/y_test.npy\", y_test)\n",
    "\n",
    "        # Does PCA simultaneously\n",
    "        # scaler.fit(X)\n",
    "        # X = scaler.transform(X)\n",
    "        pca = PCA(.95)\n",
    "        pca.fit(x_train_scale)\n",
    "        x_train_pca = pca.transform(x_train_scale)\n",
    "        x_test_pca = pca.transform(x_test_scale)\n",
    "        np.save(data_dir + \"/\" + s + \"/x_pca_train.npy\", x_train_pca)\n",
    "        np.save(data_dir + \"/\" + s + \"/x_pca_test.npy\", x_test_pca)\n",
    "        np.save(data_dir + \"/\" + s + \"/y_pca_train.npy\", y_train)\n",
    "        np.save(data_dir + \"/\" + s + \"/y_pca_test.npy\", y_test)\n",
    "        count +=1\n",
    "    \n",
    "#partition_data_balanced()\n",
    "\n",
    "def get_training_data(subject,pca,keystrokes_size):\n",
    "    \"\"\"Returns the training data partition for the given subject\"\"\"\n",
    "\n",
    "    path =  \"/Users/sloth/Desktop/CS271/271_project/DataMapping/balanced_new_data_\" + str(keystrokes_size) + \"/\"+ str(subject)\n",
    "    if pca:\n",
    "        x_path = path + \"/x_pca_train.npy\"\n",
    "        y_path = path + \"/y_pca_train.npy\"\n",
    "    else:\n",
    "        x_path = path + \"/x_train.npy\"\n",
    "        y_path = path + \"/y_train.npy\"\n",
    "\n",
    "    x_train = np.load(x_path)\n",
    "    y_train = np.load(y_path)\n",
    "\n",
    "    return x_train.astype(float), y_train.astype(float)\n",
    "\n",
    "\n",
    "def get_test_data(subject,pca, keystrokes_size):\n",
    "    \"\"\"Returns the training data partition for the given subject\"\"\"\n",
    "\n",
    "    path =  \"/Users/sloth/Desktop/CS271/271_project/DataMapping/balanced_new_data_\" + str(keystrokes_size) + \"/\"+ str(subject)\n",
    "    if pca:\n",
    "        x_path = path + \"/x_pca_test.npy\"\n",
    "        y_path = path + \"/y_pca_test.npy\"\n",
    "    else:\n",
    "        x_path = path + \"/x_test.npy\"\n",
    "        y_path = path + \"/y_test.npy\"\n",
    "\n",
    "    x_test = np.load(x_path)\n",
    "    y_test = np.load(y_path)\n",
    "\n",
    "    return x_test.astype(float), y_test.astype(float)\n",
    "\n",
    "paths = [\"/Users/sloth/Desktop/CS271/271_project/DataMapping/keystroke_new_data_50.json\"]#\"/Users/sloth/Desktop/CS271/271_project/DataMapping/keystroke_new_data_75.json\",\"/Users/sloth/Desktop/CS271/271_project/DataMapping/keystroke_new_data_50.json\"]\n",
    "# paths = [\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_data_50.json\",\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_data_75.json\",\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_data_100.json\"]\n",
    "# for p in paths:\n",
    "#     partition_data_balanced(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~Starting SVM Bagging~~~~~~~~~~\n",
      "EER: 49.92%\n",
      "ACC: 93.10%\n",
      "FAR: 0.00%\n",
      "FNR: 99.84%\n",
      "~~~~~~~~~~Starting KNN Bagging~~~~~~~~~~\n",
      "EER: 47.88%\n",
      "ACC: 92.59%\n",
      "FAR: 0.96%\n",
      "FNR: 94.80%\n",
      "~~~~~~~~~~Starting LogitBoost~~~~~~~~~~\n",
      "EER: 47.11%\n",
      "ACC: 92.84%\n",
      "FAR: 0.80%\n",
      "FNR: 93.43%\n",
      "~~~~~~~~~~Starting SVM Bagging~~~~~~~~~~\n",
      "EER: 49.57%\n",
      "ACC: 91.05%\n",
      "FAR: 0.05%\n",
      "FNR: 99.08%\n",
      "~~~~~~~~~~Starting KNN Bagging~~~~~~~~~~\n",
      "EER: 47.77%\n",
      "ACC: 90.41%\n",
      "FAR: 1.22%\n",
      "FNR: 94.32%\n",
      "~~~~~~~~~~Starting LogitBoost~~~~~~~~~~\n",
      "EER: 44.75%\n",
      "ACC: 91.04%\n",
      "FAR: 1.10%\n",
      "FNR: 88.40%\n",
      "~~~~~~~~~~Starting SVM Bagging~~~~~~~~~~\n",
      "EER: 42.66%\n",
      "ACC: 88.46%\n",
      "FAR: 0.56%\n",
      "FNR: 84.76%\n",
      "~~~~~~~~~~Starting KNN Bagging~~~~~~~~~~\n",
      "EER: 24.05%\n",
      "ACC: 90.88%\n",
      "FAR: 3.79%\n",
      "FNR: 44.30%\n",
      "~~~~~~~~~~Starting LogitBoost~~~~~~~~~~\n",
      "EER: 40.10%\n",
      "ACC: 88.66%\n",
      "FAR: 1.32%\n",
      "FNR: 78.87%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, det_curve, roc_curve, confusion_matrix, precision_recall_fscore_support, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from logitboost import LogitBoost\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from IPython.display import Image\n",
    "# from sklearn.tree import export_graphviz\n",
    "from subprocess import check_call\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "\n",
    "class Classical_Models:\n",
    "    def __init__(self,path, balanced=False):\n",
    "        self.path = path\n",
    "        self.data = read_data(path)\n",
    "        self.RF_averages = dict()\n",
    "        self.KNN_averages = dict()\n",
    "        self.SVM_averages = dict()\n",
    "        self.LOG_averages = dict()\n",
    "\n",
    "\n",
    "    def startTraining(self,pca, ratio):\n",
    "        # Trains one type of model given flags\n",
    "        self.svm_training_with_Bagging(pca,ratio)\n",
    "        self.knn_training_with_Bagging(pca,ratio)\n",
    "        self.log_training_with_LogitBoost(pca,ratio)\n",
    "        #self.rf_training_with_Grid(pca, ratio)\n",
    "\n",
    "\n",
    "    def rf_training_with_Grid(self, pca, ratio):\n",
    "        print(\"~~~~~~~~~~Starting RF Gridsearch~~~~~~~~~~\")\n",
    "\n",
    "        time_data = []\n",
    "\n",
    "        n_estimators = [int(x) for x in np.linspace(start=10, stop=10, num=10)]\n",
    "        max_features = [\"auto\", \"sqrt\"]\n",
    "        max_depth = list(range(5, 35, 10))\n",
    "\n",
    "        min_samples_split = [2, 5, 10]\n",
    "        min_samples_leaf = [1, 2, 4]\n",
    "        bootstrap = [True,False]\n",
    "        hyperparameters = dict(\n",
    "            n_estimators=n_estimators,\n",
    "            max_features=max_features,\n",
    "            # max_depth=max_depth,\n",
    "            # min_samples_split=min_samples_split,\n",
    "            # min_samples_leaf=min_samples_leaf,\n",
    "            bootstrap=bootstrap,\n",
    "        )\n",
    "        self.RF_averages[\"FAR\"] = 0\n",
    "        self.RF_averages[\"FNR\"] = 0\n",
    "        self.RF_averages[\"ACC\"] = 0\n",
    "        self.RF_averages[\"EER\"] = 0\n",
    "        count = 0\n",
    "        for s in self.data:\n",
    "            count += 1\n",
    "            X_train, Y_train = get_training_data(s,pca,int(self.path.split(\"_\")[-1].split(\".\")[0]))\n",
    "            X_train = X_train.astype(float)\n",
    "            Y_train = Y_train.astype(float)\n",
    "            rf_clf = RandomForestClassifier()\n",
    "            clf = GridSearchCV(rf_clf, hyperparameters, scoring=\"f1\", n_jobs=-1)\n",
    "            clf.fit(X_train, Y_train)\n",
    "            # print(\"Done with RF_Grid for \", s)\n",
    "            X_test, Y_test = get_test_data(s,pca,int(self.path.split(\"_\")[-1].split(\".\")[0]))\n",
    "            Y_pred = clf.predict(X_test)\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            TN = 0\n",
    "            for num in range(len(Y_pred)):\n",
    "                if(Y_pred[num] == 1.0):\n",
    "                    if(Y_test[num] == 1.0):\n",
    "                        TP += 1\n",
    "                    else:\n",
    "                        FP += 1\n",
    "                else:\n",
    "                    if(Y_test[num] == 1.0):\n",
    "                        FN += 1\n",
    "                    else:\n",
    "                        TN += 1\n",
    "            # print(\"TP\",TP,\"FP\",FP,\"FN\",FN,\"TN\",TN)\n",
    "            # print(\"Accuracy is\", accuracy_score(Y_test,Y_pred))\n",
    "            FAR = FP/(FP+TN)\n",
    "            FNR = FN/(TP+FN)\n",
    "            ACC = accuracy_score(Y_test,Y_pred)\n",
    "             # print(\"PR-F: \\n\",precision_recall_fscore_support(Y_test,Y_pred, labels= np.unique(Y_pred)))\n",
    "            fpr, tpr, thresholds = roc_curve(Y_test, Y_pred,pos_label=1.0)\n",
    "            # Calculate the EER from the ROC curve\n",
    "            eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            fnr = 1 - tpr\n",
    "            # EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "             # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "            eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            # return the mean of eer from fpr and from fnr\n",
    "            EER = (eer_1 + eer_2) / 2\n",
    "            self.RF_averages[\"FAR\"] += FAR\n",
    "            self.RF_averages[\"FNR\"] += FNR\n",
    "            self.RF_averages[\"ACC\"] += ACC \n",
    "            self.RF_averages[\"EER\"] += EER\n",
    "        self.RF_averages[\"FAR\"] /= count\n",
    "        self.RF_averages[\"FNR\"] /= count\n",
    "        self.RF_averages[\"ACC\"] /= count\n",
    "        self.RF_averages[\"EER\"] /= count\n",
    "        print(\"EER: {:.2f}%\".format((self.RF_averages[\"EER\"]/count)* 100))  \n",
    "        print(\"ACC: {:.2f}%\".format((self.RF_averages[\"ACC\"]/count)* 100))  \n",
    "        print(\"FAR: {:.2f}%\".format((self.RF_averages[\"FAR\"]/count)* 100)) \n",
    "        print(\"FNR: {:.2f}%\".format((self.RF_averages[\"FNR\"]/count)* 100)) \n",
    "        # save_time_data(ratio, \"RF\", \"RF_Grid\", pca, \"train\", sum(time_data) / len(time_data))\n",
    "        \n",
    "        \n",
    "    def svm_training_with_Bagging(self, pca, ratio):\n",
    "        print(\"~~~~~~~~~~Starting SVM Bagging~~~~~~~~~~\")\n",
    "        count = 0\n",
    "        best_model = None\n",
    "        self.SVM_averages[\"FAR\"] = 0\n",
    "        self.SVM_averages[\"FNR\"] = 0\n",
    "        self.SVM_averages[\"ACC\"] = 0\n",
    "        self.SVM_averages[\"EER\"] = 0\n",
    "        \n",
    "        for s in self.data:\n",
    "            X_train, Y_train = get_training_data(s,pca,int(self.path.split(\"_\")[-1].split(\".\")[0]))\n",
    "            X_train = X_train.astype(float)\n",
    "            Y_train = Y_train.astype(float)\n",
    "\n",
    "            sv_clf = SVC(gamma=\"auto\", decision_function_shape=\"ovr\",tol=.001)\n",
    "            bag_clf = BaggingClassifier(sv_clf, n_estimators=20)\n",
    "            bag_clf.fit(X_train, Y_train)\n",
    "            # data_dir = \"/Users/sloth/Desktop/CS271/271_project/DataMapping/balanced_models/\"\n",
    "            # if not path.isdir(data_dir):\n",
    "            #     mkdir(data_dir)\n",
    "            # print(\"Done with SVM_Bagging for\", s)\n",
    "            X_test, Y_test = get_test_data(s,pca,int(self.path.split(\"_\")[-1].split(\".\")[0]))\n",
    "            Y_pred = bag_clf.predict(X_test)\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            TN = 0\n",
    "            for num in range(len(Y_pred)):\n",
    "                if(Y_pred[num] == 1.0):\n",
    "                    if(Y_test[num] == 1.0):\n",
    "                        TP += 1\n",
    "                    else:\n",
    "                        FP += 1\n",
    "                else:\n",
    "                    if(Y_test[num] == 1.0):\n",
    "                        FN += 1\n",
    "                    else:\n",
    "                        TN += 1\n",
    "            # print(\"TP\",TP,\"FP\",FP,\"FN\",FN,\"TN\",TN)\n",
    "            # print(\"Accuracy is\", accuracy_score(Y_test,Y_pred))\n",
    "            FAR = FP/(FP+TN)\n",
    "            FNR = FN/(TP+FN)\n",
    "            ACC = accuracy_score(Y_test,Y_pred)\n",
    "            count += 1\n",
    "            # print(\"PR-F: \\n\",precision_recall_fscore_support(Y_test,Y_pred, labels= np.unique(Y_pred)))\n",
    "            fpr, tpr, thresholds = roc_curve(Y_test, Y_pred,pos_label=1.0)\n",
    "            # Calculate the EER from the ROC curve\n",
    "            fnr = 1 - tpr\n",
    "            eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "             # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "            eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            # return the mean of eer from fpr and from fnr\n",
    "            EER = (eer_1 + eer_2) / 2\n",
    "            self.SVM_averages[\"FAR\"] += FAR\n",
    "            self.SVM_averages[\"FNR\"] += FNR\n",
    "            self.SVM_averages[\"ACC\"] += ACC\n",
    "            self.SVM_averages[\"EER\"] += EER\n",
    "        self.SVM_averages[\"FAR\"] /= count\n",
    "        self.SVM_averages[\"FNR\"] /= count\n",
    "        self.SVM_averages[\"ACC\"] /= count\n",
    "        self.SVM_averages[\"EER\"] /= count\n",
    "        print(\"EER: {:.2f}%\".format((self.SVM_averages[\"EER\"])* 100))  \n",
    "        print(\"ACC: {:.2f}%\".format((self.SVM_averages[\"ACC\"])* 100))  \n",
    "        print(\"FAR: {:.2f}%\".format((self.SVM_averages[\"FAR\"])* 100)) \n",
    "        print(\"FNR: {:.2f}%\".format((self.SVM_averages[\"FNR\"])* 100)) \n",
    "           \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def knn_training_with_Bagging(self, pca, ratio):\n",
    "        print(\"~~~~~~~~~~Starting KNN Bagging~~~~~~~~~~\")\n",
    "        time_data = []\n",
    "        self.KNN_averages[\"FAR\"] = 0\n",
    "        self.KNN_averages[\"FNR\"] = 0\n",
    "        self.KNN_averages[\"ACC\"] = 0\n",
    "        self.KNN_averages[\"EER\"] = 0\n",
    "        count = 0\n",
    "        for s in self.data:\n",
    "            X_train, Y_train = get_training_data(s, pca,int(self.path.split(\"_\")[-1].split(\".\")[0]))\n",
    "            X_train = X_train.astype(float)\n",
    "            Y_train = Y_train.astype(float)\n",
    "            bagging_clf = BaggingClassifier(\n",
    "                KNeighborsClassifier(algorithm=\"brute\", metric=\"minkowski\")\n",
    "            )\n",
    "            bagging_clf.fit(X_train, Y_train)\n",
    "            X_test, Y_test = get_test_data(s,pca,int(self.path.split(\"_\")[-1].split(\".\")[0]))\n",
    "            Y_pred = bagging_clf.predict(X_test)\n",
    "            # threshold = 1.00 # set your desired threshold here\n",
    "            # Y_scores = bagging_clf.predict_proba(X_test)[:,1] # get the predicted probabilities of positive class\n",
    "            # Y_pred = (Y_scores > threshold).astype(int)\n",
    "            # print(\"Done with KNN_Bagging for\", s)\n",
    "            # fpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\n",
    "            # print(\"FPR: \",fpr, \"TPR: \",tpr,\"Thresholds: \", thresholds)\n",
    "            # print(\"Confusion Matrix\\n\",confusion_matrix(Y_test,Y_pred))\n",
    "            # print(\"Accuracy is\", accuracy_score(Y_test,Y_pred))\n",
    "            # cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(Y_test,Y_pred), display_labels = [False, True])\n",
    "            # cm_display.plot()\n",
    "            # plt.show() \n",
    "            # print(X_test.shape) \n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            TN = 0\n",
    "            for num in range(len(Y_pred)):\n",
    "                if(Y_pred[num] == 1.0):\n",
    "                    if(Y_test[num] == 1.0):\n",
    "                        TP += 1\n",
    "                    else:\n",
    "                        FP += 1\n",
    "                else:\n",
    "                    if(Y_test[num] == 1.0):\n",
    "                        FN += 1\n",
    "                    else:\n",
    "                        TN += 1\n",
    "            FAR = FP/(FP+TN)\n",
    "            FNR = FN/(TP+FN)\n",
    "            \n",
    "            ACC = accuracy_score(Y_test,Y_pred)\n",
    "            count +=1\n",
    "            # print(\"PR-F: \\n\",precision_recall_fscore_support(Y_test,Y_pred, labels= np.unique(Y_pred)))\n",
    "            fpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\n",
    "            fnr = 1 - tpr\n",
    "            eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            # EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "             # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "            eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            # return the mean of eer from fpr and from fnr\n",
    "            EER = (eer_1 + eer_2) / 2\n",
    "            self.KNN_averages[\"EER\"] += EER\n",
    "            self.KNN_averages[\"FAR\"] += FAR\n",
    "            self.KNN_averages[\"FNR\"] += FNR\n",
    "            self.KNN_averages[\"ACC\"] += ACC\n",
    "        self.KNN_averages[\"FAR\"] /= count\n",
    "        self.KNN_averages[\"FNR\"] /= count\n",
    "        self.KNN_averages[\"ACC\"] /= count\n",
    "        self.KNN_averages[\"EER\"] /= count\n",
    "        print(\"EER: {:.2f}%\".format((self.KNN_averages[\"EER\"])* 100))  \n",
    "        print(\"ACC: {:.2f}%\".format((self.KNN_averages[\"ACC\"])* 100))  \n",
    "        print(\"FAR: {:.2f}%\".format((self.KNN_averages[\"FAR\"])* 100)) \n",
    "        print(\"FNR: {:.2f}%\".format((self.KNN_averages[\"FNR\"])* 100)) \n",
    "    \n",
    "    def log_training_with_LogitBoost(self, pca, ratio):\n",
    "        time_data = []\n",
    "\n",
    "        print(\"~~~~~~~~~~Starting LogitBoost~~~~~~~~~~\")\n",
    "        count = 0\n",
    "        self.LOG_averages[\"FAR\"] = 0\n",
    "        self.LOG_averages[\"FNR\"] = 0\n",
    "        self.LOG_averages[\"ACC\"] = 0\n",
    "        self.LOG_averages[\"EER\"] = 0\n",
    "        for s in self.data:\n",
    "            X_train, Y_train = get_training_data(s, pca,int(self.path.split(\"_\")[-1].split(\".\")[0]))\n",
    "            X_train = X_train.astype(float)\n",
    "            Y_train = Y_train.astype(float)\n",
    "\n",
    "            lb_clf = LogisticRegression(penalty=\"l2\")\n",
    "            lb_clf.fit(X_train, Y_train)\n",
    "            lb_clf.fit(X_train, Y_train)\n",
    "            X_test, Y_test = get_test_data(s,pca,int(self.path.split(\"_\")[-1].split(\".\")[0]))\n",
    "            Y_pred = lb_clf.predict(X_test)    \n",
    "            # print(\"Done with LOG_LBoost for\", s)\n",
    "            # fpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\n",
    "            # print(\"FPR: \",fpr, \"TPR: \",tpr, \"Thresholds: \", thresholds)\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            TN = 0\n",
    "            for num in range(len(Y_pred)):\n",
    "                if(Y_pred[num] == 1.0):\n",
    "                    if(Y_test[num] == 1.0):\n",
    "                        TP += 1\n",
    "                    else:\n",
    "                        FP += 1\n",
    "                else:\n",
    "                    if(Y_test[num] == 1.0):\n",
    "                        FN += 1\n",
    "                    else:\n",
    "                        TN += 1\n",
    "            FAR = FP/(FP+TN)\n",
    "            FNR = FN/(TP+FN)\n",
    "            ACC = accuracy_score(Y_test,Y_pred)\n",
    "            count += 1\n",
    "            # print(\"PR-F: \\n\",precision_recall_fscore_support(Y_test,Y_pred, labels= np.unique(Y_pred)))\n",
    "            fpr, tpr, thresholds = roc_curve(Y_test, Y_pred,pos_label=1.0)\n",
    "            # Calculate the EER from the ROC curve\n",
    "            fnr = 1 - tpr\n",
    "            eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            # EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "             # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "            eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "            # return the mean of eer from fpr and from fnr\n",
    "            EER = (eer_1 + eer_2) / 2\n",
    "            # print(\"EER: {:.2f}%\".format(EER * 100))  \n",
    "            self.LOG_averages[\"FAR\"] += FAR\n",
    "            self.LOG_averages[\"FNR\"] += FNR\n",
    "            self.LOG_averages[\"ACC\"] += ACC\n",
    "            self.LOG_averages[\"EER\"] += EER\n",
    "        self.LOG_averages[\"FAR\"] /= count\n",
    "        self.LOG_averages[\"FNR\"] /= count\n",
    "        self.LOG_averages[\"ACC\"] /= count\n",
    "        self.LOG_averages[\"EER\"] /= count\n",
    "        print(\"EER: {:.2f}%\".format((self.LOG_averages[\"EER\"])* 100))  \n",
    "        print(\"ACC: {:.2f}%\".format((self.LOG_averages[\"ACC\"])* 100))  \n",
    "        print(\"FAR: {:.2f}%\".format((self.LOG_averages[\"FAR\"])* 100)) \n",
    "        print(\"FNR: {:.2f}%\".format((self.LOG_averages[\"FNR\"])* 100)) \n",
    "            # print(\"Confusion Matrix\\n\",confusion_matrix(Y_test,Y_pred))\n",
    "            # print(\"Accuracy is\", accuracy_score(Y_test,Y_pred))\n",
    "            # cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(Y_test,Y_pred), display_labels = [False, True])\n",
    "            # cm_display.plot()\n",
    "            # plt.show()  \n",
    "            \n",
    "            \n",
    "paths = [\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_new_data_100.json\",\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_new_data_75.json\",\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_new_data_50.json\"]\n",
    "#paths = [\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_data_50.json\",\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_data_75.json\",\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/keystroke_data_100.json\"]\n",
    "for p in paths:\n",
    "    rf = Classical_Models(p,balanced=True)\n",
    "    rf.startTraining(False,50)\n",
    "    # with open(\"/Users/sloth/Downloads/UB_keystroke_dataset/DataMapping/Results_data_pca_\" + p[-7:-5],'x') as F:\n",
    "    #     # Use the json dumps method to write the list to disk\n",
    "    #     Results = {\"SVM\": rf.SVM_averages, \"KNN\": rf.KNN_averages, \"LOG\": rf.LOG_averages, \"RF\": rf.RF_averages}\n",
    "    #     F.write(json.dumps(Results))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
