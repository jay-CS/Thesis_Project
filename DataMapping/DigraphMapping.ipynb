{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'ba']\n",
      "['tab', 'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p']\n",
      "['cap', 'a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l']\n",
      "['ls', 'z', 'x', 'c', 'v', 'b', 'n', 'm', 'rs']\n",
      "['space']\n",
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '0', 27: '1', 28: '2', 29: '3', 30: '4', 31: '5', 32: '6', 33: '7', 34: '8', 35: '9', 36: 'tab', 37: 'ls', 38: 'ba', 39: 'rs', 40: 'cap', 41: 'sp'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m all_samples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     56\u001b[0m mappings_for_user \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 57\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m all_files:\n\u001b[1;32m     58\u001b[0m     \u001b[39m# All samples in each files\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     samples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(np\u001b[39m.\u001b[39mload(filename))\n\u001b[1;32m     61\u001b[0m     new_samples \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_files' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# dataset_list = []\n",
    "# total = 0\n",
    "# for filename in all_files:\n",
    "#   dataset = np.load(filename)\n",
    "#   total += len(dataset)\n",
    "#   # print(dataset.shape)\n",
    "#   # dataset_list.append(dataset)\n",
    "\n",
    "# print(\"Total number of images:\", total)\n",
    "import glob \n",
    "import numpy as np\n",
    "\n",
    "# path = r\"/Users/sloth/Desktop/CS271/271_project/CNN/\"\n",
    "# all_files = glob.glob(path + \"/100/*\")\n",
    "# for i in all_files:\n",
    "#   print(\"100\", np.load(i).shape)\n",
    "# path = r\"//Users/sloth/Desktop/CS271/271_project/CNN/\"\n",
    "# all_files = glob.glob(path + \"/75/*\")\n",
    "# for i in all_files:\n",
    "#   print(\"75\",np.load(i).shape)\n",
    "# path = r\"/Users/sloth/Desktop/CS271/271_project/CNN/\"\n",
    "# all_files = glob.glob(path + \"/50/*\")\n",
    "# for i in all_files:\n",
    "#   print(\"50\",np.load(i).shape)\n",
    "\n",
    "\n",
    "# Make a keyboard, and function to determine if its middle, top, bottom\n",
    "keyboard = [\n",
    "  [x for x in \"1234567890\"] + [\"ba\"],\n",
    "  [\"tab\"] + [x for x in \"qwertyuiop\"],\n",
    "  [\"cap\"] + [x for x in \"asdfghjkl\"],\n",
    "  [\"ls\"] + [x for x in \"zxcvbnm\"] + [\"rs\"],\n",
    "  [\"space\"]\n",
    "]\n",
    "\n",
    "for k in keyboard:\n",
    "  print(k)\n",
    "\n",
    "\n",
    "#Make each pairing in each sample easily recognizable\n",
    "nums = [x for x in \"0123456789\"]\n",
    "chars = [x for x in \"abcdefghijklmnopqrstuvwxyz\"]\n",
    "spec = [\"tab\",\"ls\",\"ba\",\"rs\",\"cap\",\"sp\"]\n",
    "characters = chars + nums + spec\n",
    "dic = { k:characters[k] for k in range(len(characters))}\n",
    "print(dic)\n",
    "\n",
    "\n",
    "key_pair_hits = dict()\n",
    "# For each samples\n",
    "# Find the total number of hits in each channel, and update the channel with those pairs and times\n",
    "# Then map each of those pairs to the new mapping table, adding them to the RIGHT table and tranforming it into feature vector\n",
    "\n",
    "# So in each sample of a list of samples per puser, needs a list of dictionaries holding key-pair times for each channel\n",
    "all_samples = 0\n",
    "mappings_for_user = {}\n",
    "for filename in all_files:\n",
    "    # All samples in each files\n",
    "    \n",
    "    samples = np.array(np.load(filename))\n",
    "    new_samples = []\n",
    "    #print(samples.shape)\n",
    "    for i in range(len(samples)):\n",
    "      # Open Channels in each files\n",
    "      H_channel = {}\n",
    "      UD_channel = {}\n",
    "      DU_channel = {}\n",
    "      DD_channel = {}\n",
    "      UU_channel = {}\n",
    "      channels = samples[i]\n",
    "      all_samples += 1\n",
    "      # for c in range(len(channels)):\n",
    "      #   # Iterate through row and column in each samples\n",
    "      for r in range(len(channels[1])):\n",
    "          # print(\"Channel\", len(channels[c][0]))\n",
    "          for col in range(len(channels[1][0])):\n",
    "          #  print(channels[c][r][col],end=\" \")\n",
    "            if(channels[1][r][col] > 0):\n",
    "                # if(c == 0):\n",
    "                #   H_channel[dic[r]+ \" \" +dic[col]] = channels[c][r][col]\n",
    "                # elif(c == 1):\n",
    "                #   UD_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                # elif(c == 2):\n",
    "                #   DD_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                # elif(c == 3):\n",
    "                #   DU_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                # else:\n",
    "                #   UU_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                \n",
    "                if(dic[r]+ \" \" +dic[col] not in key_pair_hits):\n",
    "                  key_pair_hits[dic[r]+\" \" +dic[col]] = 1\n",
    "                else:\n",
    "                  key_pair_hits[dic[r]+\" \" +dic[col]] += 1\n",
    "      # new_samples.append([H_channel,UD_channel,DD_channel,DU_channel,UU_channel])\n",
    "      # print([H_channel,UD_channel,DD_channel,DU_channel,UU_channel])\n",
    "      # break\n",
    "      # print([x for x in new_samples])\n",
    "    # mappings_for_user[filename] = new_samples\n",
    "print(all_samples)\n",
    "print(key_pair_hits)\n",
    "\n",
    "pairs = [\"l w\",\"w q\",\"q 0\",\"q w\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'l w'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39msorted\u001b[39m(key_pair_hits, key\u001b[39m=\u001b[39mkey_pair_hits\u001b[39m.\u001b[39mget, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(key_pair_hits[\u001b[39m\"\u001b[39;49m\u001b[39ml w\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(key_pair_hits[\u001b[39m\"\u001b[39m\u001b[39mw q\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(key_pair_hits[\u001b[39m\"\u001b[39m\u001b[39mq 0\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'l w'"
     ]
    }
   ],
   "source": [
    "sorted(key_pair_hits, key=key_pair_hits.get, reverse=True)\n",
    "print(key_pair_hits[\"l w\"])\n",
    "print(key_pair_hits[\"w q\"])\n",
    "print(key_pair_hits[\"q 0\"])\n",
    "print(key_pair_hits[\"q w\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take list of lists of dictionaries\n",
    "# In each list of dictionaries \n",
    "# Map each key pair to correct category, update the UD,DD,DU,UU times, at the end \n",
    "import os\n",
    "# Make a keyboard, and function to determine if its middle, top, bottom\n",
    "keyboard = [\n",
    "  [\"~\"] + [x for x in \"1234567890\"] + [\"-\", \"=\",\"ba\"],\n",
    "  [\"tab\"] + [x for x in \"qwertyuiop\"] + [\"[\", \"]\",\"fs\"],\n",
    "  [\"cap\"] + [x for x in \"asdfghjkl\"] + [\":\", \"'\",\"na\",\"na\"],\n",
    "  [\"ls\"] + [x for x in \"zxcvbnm\"] + [\",\", \".\",\"/\",\"rs\",\"rs\",\"rs\"],\n",
    "  [\"na\",\"na\",\"na\",\"sp\",\"sp\",\"sp\",\"sp\",\"sp\",\"na\",\"na\",\"na\",\"na\",\"na\",\"na\"]\n",
    "]\n",
    "keyboard_positions = {}\n",
    "all_key_pairs = []\n",
    "for x in range(len(keyboard)):\n",
    "    for y in range(len(keyboard[0])):\n",
    "        keyboard_positions[keyboard[x][y]] = [x,y]\n",
    "\n",
    "print(keyboard_positions)\n",
    "l_dict = [x for x in \"12345\"] +  [\"tab\"] + [x for x in \"qwert\"] + [\"cap\"] + [x for x in \"asdfg\"] + [\"ls\"] + [x for x in \"zxcv\"] + [\"sp\"]\n",
    "l_dict = {l_dict[i]:i for i in range(len(l_dict))}\n",
    "print(l_dict)\n",
    "\n",
    "#Gather all possible key-pair mappings in characters list\n",
    "for x in range(len(characters)):\n",
    "    for y in range(len(characters)):\n",
    "       all_key_pairs.append([characters[x],characters[y]])\n",
    "\n",
    "#print(all_key_pairs)\n",
    "# For all keypairs find their matching catgory via BFS (i. 0L,1L,2B)\n",
    "key_pair_mappings = {}\n",
    "\n",
    "import queue\n",
    "\n",
    "mappings = { \n",
    "        #\"[H,UU,DD,DU,UD]\"\n",
    "    \"0L\": [0,0,0,0,0],\n",
    "    \"0B\": [0,0,0,0,0],\n",
    "    \"0R\": [0,0,0,0,0],\n",
    "    \"1L\": [0,0,0,0,0],\n",
    "    \"1B\": [0,0,0,0,0],\n",
    "    \"1R\": [0,0,0,0,0],\n",
    "    \"2L\": [0,0,0,0,0],\n",
    "    \"2B\": [0,0,0,0,0],\n",
    "    \"2R\": [0,0,0,0,0],\n",
    "    \"NL\": [0,0,0,0,0],\n",
    "    \"NB\": [0,0,0,0,0],\n",
    "    \"NR\": [0,0,0,0,0],\n",
    "    }\n",
    "\n",
    "\n",
    "counts= { x : 0 for x in mappings.keys()}\n",
    "\n",
    "#print(counts)\n",
    "\n",
    "def bfs():\n",
    "    \n",
    "    for x in all_key_pairs:\n",
    "        \n",
    "        #Find if keys are L,R,B\n",
    "        #print(\"First Pair\", x)\n",
    "        \n",
    "        def find_side(x):\n",
    "            side_tag = \"\"\n",
    "            side_tag += \"L\" if x[0] in l_dict else \"R\"\n",
    "            side_tag += \"L\" if x[1] in l_dict else \"R\"\n",
    "            \n",
    "            if(side_tag == \"LR\" or side_tag == \"RL\"):\n",
    "                side_tag = \"B\"\n",
    "            \n",
    "            elif(side_tag == \"LL\"):\n",
    "                side_tag = \"L\"\n",
    "             \n",
    "            else:\n",
    "                side_tag = \"R\"\n",
    "                \n",
    "            return side_tag\n",
    "        \n",
    "        side_tag = find_side(x)\n",
    "        \n",
    "        #print(\"TAG is\", side_tag)\n",
    "        #find position of first letter in keyboard (x[0]) \n",
    "        \n",
    "        #Do level by level BFS finding x[1] \n",
    "        \n",
    "        #For intial character and subsequent characters, at starting position\n",
    "        \n",
    "        #Go UP one, and UP one to right \n",
    "        \n",
    "        #Go LEFT, RIGHT\n",
    "        \n",
    "        #Go DOWN one, and DOWN one to the left \n",
    "        \n",
    "        #Peform the same 3 steps at every key in the BFS\n",
    "        \n",
    "        #Once key is found with BFS \n",
    "        start,finish = x\n",
    "        q = queue.Queue()\n",
    "        q.put(keyboard_positions[start])\n",
    "        adjency_count = 0\n",
    "        s = []\n",
    "        key_dict = {x[0]: 0}\n",
    "        if(start != finish):\n",
    "            while(not q.empty()):\n",
    "                x,y = q.get()\n",
    "                # print(x,y)\n",
    "                #Add UP neighbors\n",
    "                if(x-1 >= 0 and keyboard[x-1][y] not in key_dict ):\n",
    "                    key_dict[keyboard[x-1][y]] = 0\n",
    "                    s.append([x-1,y])\n",
    "                    \n",
    "                if(x-1 >= 0 and y+1 < len(keyboard) and keyboard[x-1][y+1] not in key_dict):\n",
    "                    key_dict[keyboard[x-1][y+1]] = 0\n",
    "                    s.append([x-1,y+1])\n",
    "                    \n",
    "                #Add LEFT RIGHT neighbors\n",
    "                if(y-1 >= 0 and keyboard[x][y-1] not in key_dict):\n",
    "                    key_dict[keyboard[x][y-1]] = 0\n",
    "                    s.append([x,y-1])\n",
    "                \n",
    "                if(y+1 < len(keyboard) and keyboard[x][y+1] not in key_dict ):\n",
    "                    key_dict[keyboard[x][y+1]] = 0\n",
    "                    s.append([x,y+1])\n",
    "\n",
    "                #Add Down neighbors\n",
    "                if(x+1 < len(keyboard) and keyboard[x+1][y] not in key_dict):\n",
    "                    key_dict[keyboard[x+1][y]] = 0\n",
    "                    s.append([x+1,y])\n",
    "                \n",
    "                if(x+1 < len(keyboard) and y-1 >= 0 and keyboard[x+1][y-1] not in key_dict ):\n",
    "                    key_dict[keyboard[x+1][y-1]] = 0\n",
    "                    s.append([x+1,y-1])\n",
    "                    \n",
    "                if(finish in key_dict):\n",
    "                    break\n",
    "               \n",
    "                if(q.empty()):\n",
    "                    for char in s:\n",
    "                        q.put(char)\n",
    "                    adjency_count += 1\n",
    "                    s = []\n",
    "          \n",
    "        tag = str(adjency_count) + side_tag if adjency_count < 3 else \"N\"+side_tag\n",
    "        key_pair_mappings[start + \" \" + finish] = tag\n",
    "        counts[tag] += 1\n",
    "    #     print(\"DONE\")\n",
    "    # print(sum([x for x in counts.values()]))\n",
    "    return key_pair_mappings\n",
    "        \n",
    "    \n",
    "# In function every sample gets a mappings dict, iterate through sample pairs and place them in their \n",
    "# appropiate category, update appropiate slot in category, then update duration of letter pressed in each one (possibly)\n",
    "# Then combine all lists to form feature vector \n",
    "\n",
    "bfs()\n",
    "\n",
    "def update_mappings(key,count,channel,time):\n",
    "    mappings[key][channel] = (mappings[key][channel] + time)/count\n",
    "    return \n",
    "    \n",
    "def clear_mapping():\n",
    "    for k in mappings.keys():\n",
    "        mappings[k] = [0,0,0,0,0]\n",
    "    return \n",
    "\n",
    "def proccess_sample(samples):\n",
    "    feature_vectors = list()\n",
    "    for s in samples:\n",
    "        # iterate through each dictionary (channel)\n",
    "        for channel in range(len(s)):\n",
    "            count = 0 \n",
    "            for x in s[channel].keys():\n",
    "                key = key_pair_mappings[x]\n",
    "                time = s[channel][x]\n",
    "                update_mappings(key,count+1,channel,time)\n",
    "        feature_vector = sum(mappings.values(),[])\n",
    "        feature_vectors.append(feature_vector)\n",
    "        clear_mapping()      \n",
    "    return feature_vectors \n",
    "        \n",
    "# REMAINING - transform new_samples into numpy feature vectors and store them in respective user folder\n",
    "# Process data and run ML algorithsm\n",
    "# Split into positive, negative 70/30\n",
    "# Run ML\n",
    "folder = [r\"/Users/sloth/Desktop/CS271/271_project/Data/50/*\"]\n",
    "def main(): \n",
    "    for path in folder:\n",
    "  # Open File\n",
    "        all_files = glob.glob(path)\n",
    "        all_files.sort()\n",
    "        mappings_for_user = {}\n",
    "        for filename in all_files:\n",
    "            # All samples in each files\n",
    "            samples = np.load(filename)\n",
    "            new_samples = []\n",
    "            print(samples.shape,filename)\n",
    "            for i in range(len(samples)):\n",
    "            # Open Channels in each files\n",
    "                H_channel = {}\n",
    "                UD_channel = {}\n",
    "                DU_channel = {}\n",
    "                DD_channel = {}\n",
    "                UU_channel = {}\n",
    "                channels = samples[i]\n",
    "                for c in range(len(channels)):\n",
    "                    # Iterate through row and column in each samples\n",
    "                    for r in range(len(channels[c])):\n",
    "                        # print(\"Channel\", len(channels[c][0]))\n",
    "                        for col in range(len(channels[c][0])):\n",
    "                        #  print(channels[c][r][col],end=\" \")\n",
    "                            if(channels[c][r][col] > 0):\n",
    "                                if(c == 0):\n",
    "                                    H_channel[dic[r]+ \" \" +dic[col]] = channels[c][r][col]\n",
    "                                elif(c == 1):\n",
    "                                    UD_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                                elif(c == 2):\n",
    "                                    DD_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                                elif(c == 3):\n",
    "                                    DU_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                                else:\n",
    "                                    UU_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                new_samples.append([H_channel,UD_channel,DD_channel,DU_channel,UU_channel])\n",
    "            # print([x for x in new_samples])\n",
    "            mappings_for_user[filename] = new_samples  \n",
    "            \n",
    "        new_samples = dict() \n",
    "        for fname in mappings_for_user.keys():\n",
    "            out = proccess_sample(mappings_for_user[fname])\n",
    "            os.mkdir(r\"/Users/sloth/Desktop/CS271/271_project/DataMapping/CNN/50/\"+fname.split(\"/\")[-1][:-4]+\"/\")\n",
    "            count = 0\n",
    "            print(len(out),fname)\n",
    "            for s in out:\n",
    "                np_array = np.array(s)\n",
    "                np.save(r\"/Users/sloth/Desktop/CS271/271_project/DataMapping/CNN/50/\"+fname.split(\"/\")[-1][:-4]+\"/\"+str(count)+\".npy\",np_array)\n",
    "                count += 1\n",
    "    \n",
    "# 59 49 55 52 47\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = [r\"/Users/sloth/Desktop/CS271/271_project/Data/50/*\"]\n",
    "pairs = [\"l w\",\"w q\",\"q 0\",\"q w\"]\n",
    "\n",
    "# Will go through each channel of every sample, and record the time for each pair listed above\n",
    "# if a pair does not exist, np.nan if placed there\n",
    "def proccess_sample(samples):\n",
    "    feature_vectors = list()\n",
    "    for s in samples:\n",
    "        # iterate through each dictionary (channel)\n",
    "        feature_vector = list()\n",
    "        for channel in range(len(s)):\n",
    "            if(channel != 0):\n",
    "                for pair in pairs:\n",
    "                    if(pair not in s[channel]):\n",
    "                        feature_vector.append(np.nan)\n",
    "                    else:\n",
    "                        feature_vector.append(s[channel][pair])\n",
    "        feature_vectors.append(feature_vector)   \n",
    "    return feature_vectors \n",
    "\n",
    "\n",
    "\n",
    "def main(): \n",
    "    for path in folder:\n",
    "        # Open File\n",
    "        all_files = glob.glob(path)\n",
    "        \n",
    "        mappings_for_user = {}\n",
    "        for filename in all_files:\n",
    "            # All samples in each files\n",
    "            samples = np.load(filename)\n",
    "            new_samples = []\n",
    "            for i in range(len(samples)):\n",
    "            # Open Channels in each files\n",
    "                H_channel = {}\n",
    "                UD_channel = {}\n",
    "                DU_channel = {}\n",
    "                DD_channel = {}\n",
    "                UU_channel = {}\n",
    "                channels = samples[i]\n",
    "                for c in range(len(channels)):\n",
    "                    # Iterate through row and column in each samples\n",
    "                    for r in range(len(channels[c])):\n",
    "                        # print(\"Channel\", len(channels[c][0]))\n",
    "                        for col in range(len(channels[c][0])):\n",
    "                        #  print(channels[c][r][col],end=\" \")\n",
    "                            if(channels[c][r][col] > 0):\n",
    "                                if(c == 0):\n",
    "                                    H_channel[dic[r]+ \" \" +dic[col]] = channels[c][r][col]\n",
    "                                elif(c == 1):\n",
    "                                    UD_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                                elif(c == 2):\n",
    "                                    DD_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                                elif(c == 3):\n",
    "                                    DU_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                                else:\n",
    "                                    UU_channel[dic[r]+\" \" +dic[col]] = channels[c][r][col]\n",
    "                new_samples.append([H_channel,UD_channel,DD_channel,DU_channel,UU_channel])\n",
    "            # print([x for x in new_samples])\n",
    "            mappings_for_user[filename] = new_samples \n",
    "        new_samples = dict() \n",
    "        for fname in mappings_for_user.keys():\n",
    "            out = proccess_sample(mappings_for_user[fname])\n",
    "            os.mkdir(r\"/Users/sloth/Desktop/CS271/271_project/DataMapping/CNN_new/50/\"+fname.split(\"/\")[-1][:-4]+\"/\")\n",
    "            count = 0\n",
    "            for s in out:\n",
    "                np_array = np.array(s)\n",
    "                np.save(r\"/Users/sloth/Desktop/CS271/271_project/DataMapping/CNN_new/50/\"+fname.split(\"/\")[-1][:-4]+\"/\"+str(count)+\".npy\",np_array)\n",
    "                count += 1\n",
    "        \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "            \n",
    "#Finding mean of every column, and replacing np.nan with these values\n",
    "path = r\"/Users/sloth/Desktop/CS271/271_project/DataMapping/CNN_new/50/\"\n",
    "\n",
    "def save_new_features(samples,paths):\n",
    "    count = 0\n",
    "    os.mkdir(paths)\n",
    "    for s in samples:\n",
    "        np_array = np.array(s)\n",
    "        np.save(paths+str(count)+\".npy\",np_array)\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "def new_features():\n",
    "    for s in range(1,76):\n",
    "        id = \"00\" + str(s) if s < 10 else \"0\" + str(s)\n",
    "        all_files = glob.glob(path + id + \"/*\")\n",
    "        vectors = list()\n",
    "        for file in all_files:\n",
    "            # print(file)\n",
    "            vectors.append(np.load(file))\n",
    "        vectors = np.array(vectors)\n",
    "        col_mean = np.nanmean(vectors, axis = 0)\n",
    "        # Find column mean and replace np.nan values\n",
    "        # print (\"columns mean\", str(col_mean))\n",
    "        # find indices where nan value is present\n",
    "        inds = np.where(np.isnan(vectors))\n",
    "        # replace inds with avg of column\n",
    "        vectors[inds] = np.take(col_mean, inds[1])\n",
    "        save_new_features(vectors,r\"/Users/sloth/Desktop/CS271/271_project/DataMapping/new_data_50/\" + id+\"/\")\n",
    "        #print(vectors.shape)\n",
    "\n",
    "def convertoJson():\n",
    "    with open('/Users/sloth/Desktop/CS271/271_project/DataMapping/keystroke_new_data_50.json', 'x') as F:\n",
    "        # Use the json dumps method to write the list to disk\n",
    "        all_data = {}\n",
    "        for i in range(1,76):\n",
    "            s = \"00\" + str(i) if i < 10 else \"0\" + str(i)\n",
    "            all_files = glob.glob(\"/Users/sloth/Desktop/CS271/271_project/DataMapping/new_data_50/%s/*\"%(s))\n",
    "            data = []\n",
    "            for file in all_files:\n",
    "                data.append(list(np.load(file)))\n",
    "            all_data[\"user\"+str(i)] = data\n",
    "        F.write(json.dumps(all_data))\n",
    "\n",
    "new_features()\n",
    "convertoJson()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
