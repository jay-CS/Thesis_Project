{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size = 4, stride = 2, padding =1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d*2,4,2,1,),\n",
    "            self._block(features_d*2, features_d*4,4,2,1,),\n",
    "            self._block(features_d*4, features_d*8,4,2,1,),\n",
    "            nn.Conv2d(features_d*8, 1,  kernel_size= 4, stride = 2, padding = 0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias = False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self._block(z_dim, features_g*16, 4, 1, 0),\n",
    "            self._block(features_g*16, features_g*8, 4, 2, 1),\n",
    "            self._block(features_g*8, features_g*4, 4, 2, 1 ),\n",
    "            self._block(features_g*4, features_g*2, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g*2, channels_img, kernel_size=4, stride = 2, padding = 1\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias = False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "def initialize_weights (model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,(nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, .02)\n",
    "            \n",
    "def test():\n",
    "    N, in_channels, H,W = 8, 3, 64, 64\n",
    "    z_dim = 100\n",
    "    x = torch.randn((N,in_channels, H,W))\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    initialize_weights(disc)\n",
    "    assert disc(x).shape == (N,1,1,1)\n",
    "    gen = Generator(z_dim, in_channels, 8)\n",
    "    initialize_weights(gen)\n",
    "    z = torch.randn((N,z_dim,1,1))\n",
    "    assert gen(z).shape == (N,in_channels, H,W)\n",
    "    print(\"success\")\n",
    "    \n",
    "    \n",
    "test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of subjects: 75\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "path = r\"/home/jupyter/src/Thesis_Project/Data/50\"\n",
    "all_files = glob.glob(path + \"/*\")\n",
    "print(\"Total number of subjects:\", len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 40000\n",
    "def extract_samples(target):\n",
    "    positive_data = None\n",
    "    negative_data = None\n",
    "\n",
    "    positive_init = False\n",
    "    negative_init = False\n",
    "\n",
    "    positive_indices = None\n",
    "    negative_indices = None\n",
    "\n",
    "    print('**********************', target)\n",
    "    for i, filename in enumerate(all_files):\n",
    "        if i == target:\n",
    "            positive_dataset = np.load(filename)\n",
    "            positive_indices = list(range(len(positive_dataset)))\n",
    "            np.random.shuffle(positive_indices)\n",
    "            positive_init = True\n",
    "            positive_data = positive_dataset[positive_indices]\n",
    "            print(\"Current positive keystroke images Data shape is\",positive_data.shape)\n",
    "\n",
    "    positive_length = len(positive_data)\n",
    "    negative_length = total - positive_length\n",
    "\n",
    "    for i, filename in enumerate(all_files):\n",
    "        if i != target:\n",
    "            negative_dataset = np.load(filename)\n",
    "            nega_len = len(negative_dataset)\n",
    "            if random.randint(0, 1) == 0:\n",
    "                smaple_len = math.floor(nega_len/negative_length * positive_length)\n",
    "            else:\n",
    "                smaple_len = math.ceil(nega_len/negative_length * positive_length)\n",
    "            negative_indices = list(range(nega_len))\n",
    "\n",
    "            if not negative_init:\n",
    "                negative_data = negative_dataset[negative_indices[:smaple_len]]\n",
    "                negative_init = True\n",
    "            else:\n",
    "                extend_sameple = negative_dataset[negative_indices[:smaple_len]]\n",
    "                negative_data = np.concatenate((negative_data, extend_sameple), axis=0)\n",
    "\n",
    "            print(\"Current negative keystroke images Data shape is\", negative_data.shape)\n",
    "\n",
    "    print(\"Finaly positive keystroke images Data shape is\",positive_data.shape)\n",
    "    print(\"Finaly negative keystroke images Data shape is\", negative_data.shape)\n",
    "\n",
    "    return positive_data, negative_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeystrokesDataset(Dataset):\n",
    "    def __init__(self, samples, labels, transform):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        x = self.samples[idx]\n",
    "        x = x.transpose((1, 2 ,0))\n",
    "        x = self.transform(image=x)['image']\n",
    "        label = torch.from_numpy(self.labels[idx]).float()\n",
    "        return x, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encapsulate(positive_data, negative_data):\n",
    "\n",
    "    train_dataloaders = []\n",
    "    test_dataloaders = []\n",
    "  \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "    total_dataset = np.concatenate((positive_data, negative_data), axis = 0)\n",
    "    total_labels = np.concatenate((\n",
    "      np.ones((len(positive_data), 1)), \n",
    "      np.zeros((len(negative_data), 1))\n",
    "    ), axis=0)\n",
    "\n",
    "    for train_index, test_index in skf.split(total_dataset, total_labels):\n",
    "        train_dataset_numpy, test_dataset_numpy = total_dataset[train_index], total_dataset[test_index]\n",
    "        train_labels_numpy, test_labels_numpy = total_labels[train_index], total_labels[test_index]\n",
    "\n",
    "        mean = 0.\n",
    "        std = 0.\n",
    "\n",
    "        batch_samples = len(train_dataset_numpy) # batch size (the last batch can have smaller size!)\n",
    "        images = train_dataset_numpy.reshape(batch_samples, 5, -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "\n",
    "        mean /= len(train_dataset_numpy)\n",
    "        std /= len(train_dataset_numpy)\n",
    "\n",
    "    # transform = transforms.Compose([\n",
    "    #   transforms.Normalize(mean=mean,std=std)\n",
    "    # ])\n",
    "\n",
    "    train_transform = A.Compose([\n",
    "        A.Normalize(mean=mean.tolist(), std=std.tolist(), max_pixel_value=1.0, p=1.0),\n",
    "        A.CoarseDropout(p=0.5, max_height=3, max_width=3, fill_value=0),\n",
    "        # A.Cutout(p=0.5, max_h_size=3, max_w_size=3, fill_value=0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p=1.)\n",
    "\n",
    "    test_transform = A.Compose([\n",
    "        A.Normalize(mean=mean.tolist(), std=std.tolist(), max_pixel_value=1.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p=1.)\n",
    "\n",
    "\n",
    "    train_dataset = KeystrokesDataset(train_dataset_numpy, train_labels_numpy, train_transform)\n",
    "    test_dataset = KeystrokesDataset(test_dataset_numpy, test_labels_numpy, test_transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    train_dataloaders.append(train_dataloader)\n",
    "    test_dataloaders.append(test_dataloader)\n",
    "\n",
    "    return train_dataloaders, test_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** 0\n",
      "Current positive keystroke images Data shape is (357, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (2, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (5, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (8, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (10, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (13, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (16, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (18, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (22, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (25, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (29, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (32, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (35, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (39, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (41, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (44, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (47, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (51, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (54, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (57, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (59, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (61, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (64, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (68, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (72, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (75, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (78, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (80, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (84, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (87, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (90, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (94, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (96, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (100, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (102, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (104, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (108, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (111, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (114, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (117, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (120, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (124, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (127, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (131, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (134, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (136, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (139, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (143, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (146, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (149, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (152, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (154, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (157, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (160, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (164, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (167, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (170, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (172, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (175, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (178, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (180, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (184, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (187, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (189, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (193, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (196, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (200, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (203, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (206, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (210, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (212, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (215, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (217, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (219, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (222, 5, 42, 42)\n",
      "Finaly positive keystroke images Data shape is (357, 5, 42, 42)\n",
      "Finaly negative keystroke images Data shape is (222, 5, 42, 42)\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_18492/1156076106.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOISE_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\"if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 5\n",
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 5 \n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [.5 for _ in range(CHANNELS_IMG)], [.5 for _ in range(CHANNELS_IMG)]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# dataset = datasets.MNIST(root=\"dataset/\", train= True, transform = transforms, download = True)\n",
    "# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "data = extract_samples(0)\n",
    "dataloader = encapsulate(data[0],data[1])\n",
    "gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas = (.5, .999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas = (.5, .999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(32, NOISE_DIM, 1,1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "disc.train()\n",
    "\n",
    "print(len(dataloader))\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (real,_) in enumerate(dataloader[0]):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn((BATCH_SIZE, NOISE_DIM, 1,1), device = device)\n",
    "        fake = gen(noise)\n",
    "        \n",
    "        \n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).reshape(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake ) /2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "        \n",
    "        \n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** 0\n",
      "Current positive keystroke images Data shape is (357, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (2, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (4, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (7, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (9, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (11, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (13, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (15, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (19, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (22, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (25, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (27, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (29, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (32, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (35, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (38, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (41, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (44, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (47, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (51, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (54, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (57, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (61, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (65, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (69, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (72, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (74, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (76, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (80, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (83, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (85, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (89, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (91, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (94, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (97, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (100, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (103, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (106, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (109, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (112, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (115, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (119, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (123, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (127, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (131, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (134, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (138, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (141, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (144, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (148, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (152, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (155, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (158, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (162, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (165, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (168, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (172, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (175, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (177, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (179, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (181, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (184, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (186, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (189, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (192, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (194, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (198, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (200, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (203, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (206, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (209, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (213, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (216, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (219, 5, 42, 42)\n",
      "Current negative keystroke images Data shape is (221, 5, 42, 42)\n",
      "Finaly positive keystroke images Data shape is (357, 5, 42, 42)\n",
      "Finaly negative keystroke images Data shape is (221, 5, 42, 42)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 4, 4], expected input[64, 5, 42, 42] to have 1 channels, but got 5 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_18492/828042803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mdisc_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mloss_disc_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdisc_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/ipykernel_18492/2278069707.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 460\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 4, 4], expected input[64, 5, 42, 42] to have 1 channels, but got 5 channels instead"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\"if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 5\n",
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 5 \n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [.5 for _ in range(CHANNELS_IMG)], [.5 for _ in range(CHANNELS_IMG)]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# dataset = datasets.MNIST(root=\"dataset/\", train= True, transform = transforms, download = True)\n",
    "# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "data = extract_samples(0)\n",
    "dataloader,dataloader2 = encapsulate(data[0],data[1])\n",
    "gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas = (.5, .999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas = (.5, .999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(32, NOISE_DIM, 1,1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "disc.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (real,_) in enumerate(dataloader[0]):\n",
    "            \n",
    "        #inputs = inputs.to(device).half() # uncomment for half precision model\n",
    "    \n",
    "        real = real.to(device)\n",
    "        noise = torch.randn((BATCH_SIZE, NOISE_DIM, 1,1), device = device)\n",
    "        fake = gen(noise)\n",
    "        \n",
    "        \n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).reshape(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake ) /2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "        \n",
    "        \n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
